{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJr7gbDG5Pa4amfIpaNtuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christofferaakre/machine-learning/blob/master/projects/mnist/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1bgWwKhj10n"
      },
      "source": [
        "# mnist <!-- omit in toc -->\n",
        "[mnist](http://yann.lecun.com/exdb/mnist/) \n",
        "is a database of images of handwritten digits, in particular, a set of 60,000 training examples and 10,000 test examples.\n",
        "\n",
        "## goal of this project\n",
        "Write a neural network that can recognise the handwritten digits from the `mnist` dataset.\n",
        "\n",
        "## results \n",
        "The neural network was trained on `60 000` training examples, and then tested on `10 000` more examples. I trained for 100 epochs using SGD with a batch size of `100`, which took approximately 5-10 minutes using the free GPU acceleration in Google Colab. The results were:\n",
        "```\n",
        "Correct: 9873 Incorrect: 127\n",
        "Accuracy: 0.9872999787330627\n",
        "```\n",
        "These are very good results in my opinion, and were achieved with very little effort. I got these results the first time I trained the network, I didn't even have to tweak anything.\n",
        "## input data\n",
        "`28x28` images representing handwritten digits from `0-9`, represented as a `1x28x28` tensor since the images are greyscale images.\n",
        "the images were accessed using `torchvision.datasets.MNIST`\n",
        "## output\n",
        "A `10D vector` with probabilities for the given digit being each of the 10 digits for `0-9`. For example, if a particular input digit is `3`, we would want a perfect neural network to return \n",
        "```\n",
        "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
        "``` \n",
        "and then it would have zero error.\n",
        "\n",
        "## model\n",
        "1. `1x28x28` input --> `3x3` conv (`1` in, `6` out) --> `26x26`\n",
        "2. `relu`\n",
        "3. `26x26` --> `3x3` conv (`6` in, `16` out) --> `24x24`\n",
        "4. `relu`\n",
        "5. `Linear` (`16 * 24 * 24` in, `120` out)\n",
        "6. `relu`\n",
        "7. `Linear` (`120` in, `84` out)\n",
        "8. `relu`\n",
        "9. `Linear` (`84` in, `10` out)\n",
        "10. `MSELoss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v_tMivXj4xw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "              transforms.ToTensor()\n",
        "])\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "training_data= torchvision.datasets.MNIST(root='./mnist',\n",
        "                                          train=True,\n",
        "                                          download=True,\n",
        "                                          transform=transform\n",
        "                                          )\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              )\n",
        "\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root='./mnist',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform\n",
        "                                       )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True\n",
        "                                          )\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Lzq_HOnAiw",
        "outputId": "46288265-65cd-4cc3-ae81-40e6858a137b"
      },
      "source": [
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28])\n",
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-3_s1hkOp-Rf",
        "outputId": "ca22f864-179c-4d67-aa41-4656cf843f3a"
      },
      "source": [
        "# showing images to check the dataset was imported\n",
        "# correctly\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(images[0][0].numpy())\n",
        "print(labels[0])\n",
        "plt.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMiEaDN8qcpa"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                           out_channels=6,\n",
        "                           kernel_size=(3, 3)\n",
        "                           )\n",
        "    self.conv2 = nn.Conv2d(in_channels=6,\n",
        "                           out_channels=16,\n",
        "                           kernel_size=(3, 3)\n",
        "                           )\n",
        "    \n",
        "    self.layer1 = nn.Linear(16 * 24 * 24, 120)\n",
        "    self.layer2 = nn.Linear(120, 84)\n",
        "    self.layer3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "     x = F.relu(self.conv1(x))\n",
        "     x = F.relu(self.conv2(x))\n",
        "     x = x.view(-1, 16 * 24 * 24)\n",
        "     x = F.relu(self.layer1(x))\n",
        "     x = F.relu(self.layer2(x))\n",
        "     x = self.layer3(x)\n",
        "     return x"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dilyo2YZuB-S",
        "outputId": "cac1558a-3d1d-446e-90e5-dfda676280a6"
      },
      "source": [
        "net = Net()\n",
        "optimizer = optim.SGD(params=net.parameters(), lr=0.1)\n",
        "criterion = nn.MSELoss()\n",
        "PATH = './mnist_net_pth'\n",
        "print(PATH)\n",
        "print(net)\n",
        "print(optimizer)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./mnist_net_pth\n",
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (layer1): Linear(in_features=9216, out_features=120, bias=True)\n",
            "  (layer2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (layer3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_1u7KF_uMGX",
        "outputId": "76343e03-8a9f-4f41-b61e-9ec34e129200"
      },
      "source": [
        "# uncomment this cell and run it once to train, then\n",
        "# comment it out again so you don't need to train it each time\n",
        "\n",
        "\n",
        "# train on GPU\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# print(device)\n",
        "# net.to(device)\n",
        "# \n",
        "# \n",
        "# epochs = 100\n",
        "# n_batches = len(training_data) // batch_size\n",
        "# \n",
        "# for epoch in range(epochs):\n",
        "#   total_loss = 0\n",
        "#   for i, data in enumerate(training_loader):\n",
        "#     optimizer.zero_grad()\n",
        "#     images, labels = data[0].to(device), data[1].to(device)\n",
        "#     targets = F.one_hot(labels, num_classes=10)\n",
        "#     outputs = net(images)\n",
        "#     _, pred = outputs.max(1)\n",
        "#     loss = criterion(outputs, targets.float())\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     total_loss += loss\n",
        "#   avg_loss = total_loss / batch_size\n",
        "#   for g in optimizer.param_groups:\n",
        "#     g['lr'] *= 0.99\n",
        "#   print(f'Epoch: {epoch + 1} Loss: {avg_loss}') \n",
        "# \n",
        "# torch.save(net.state_dict(), PATH)\n",
        "# print('training finished, and state saved')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch: 1 Loss: 0.2519228458404541\n",
            "Epoch: 2 Loss: 0.11329012364149094\n",
            "Epoch: 3 Loss: 0.09160222113132477\n",
            "Epoch: 4 Loss: 0.07978638261556625\n",
            "Epoch: 5 Loss: 0.07158755511045456\n",
            "Epoch: 6 Loss: 0.06590541452169418\n",
            "Epoch: 7 Loss: 0.061274755746126175\n",
            "Epoch: 8 Loss: 0.057786040008068085\n",
            "Epoch: 9 Loss: 0.05445444956421852\n",
            "Epoch: 10 Loss: 0.05190350487828255\n",
            "Epoch: 11 Loss: 0.04973096400499344\n",
            "Epoch: 12 Loss: 0.04765711724758148\n",
            "Epoch: 13 Loss: 0.045723073184490204\n",
            "Epoch: 14 Loss: 0.04411644488573074\n",
            "Epoch: 15 Loss: 0.04270824417471886\n",
            "Epoch: 16 Loss: 0.041341252624988556\n",
            "Epoch: 17 Loss: 0.03988884016871452\n",
            "Epoch: 18 Loss: 0.03869852051138878\n",
            "Epoch: 19 Loss: 0.03749151900410652\n",
            "Epoch: 20 Loss: 0.03638068214058876\n",
            "Epoch: 21 Loss: 0.03534592315554619\n",
            "Epoch: 22 Loss: 0.034357476979494095\n",
            "Epoch: 23 Loss: 0.03354530408978462\n",
            "Epoch: 24 Loss: 0.03251373767852783\n",
            "Epoch: 25 Loss: 0.03167903423309326\n",
            "Epoch: 26 Loss: 0.030954986810684204\n",
            "Epoch: 27 Loss: 0.030176831409335136\n",
            "Epoch: 28 Loss: 0.02935825102031231\n",
            "Epoch: 29 Loss: 0.028663022443652153\n",
            "Epoch: 30 Loss: 0.02803060971200466\n",
            "Epoch: 31 Loss: 0.02740192599594593\n",
            "Epoch: 32 Loss: 0.02683548629283905\n",
            "Epoch: 33 Loss: 0.02620137855410576\n",
            "Epoch: 34 Loss: 0.02568020299077034\n",
            "Epoch: 35 Loss: 0.025104839354753494\n",
            "Epoch: 36 Loss: 0.024615954607725143\n",
            "Epoch: 37 Loss: 0.024088110774755478\n",
            "Epoch: 38 Loss: 0.023652810603380203\n",
            "Epoch: 39 Loss: 0.02319258637726307\n",
            "Epoch: 40 Loss: 0.022745417430996895\n",
            "Epoch: 41 Loss: 0.022351188585162163\n",
            "Epoch: 42 Loss: 0.02192356251180172\n",
            "Epoch: 43 Loss: 0.021594366058707237\n",
            "Epoch: 44 Loss: 0.02116098813712597\n",
            "Epoch: 45 Loss: 0.020806314423680305\n",
            "Epoch: 46 Loss: 0.020416514948010445\n",
            "Epoch: 47 Loss: 0.020130926743149757\n",
            "Epoch: 48 Loss: 0.019805172458291054\n",
            "Epoch: 49 Loss: 0.019494913518428802\n",
            "Epoch: 50 Loss: 0.0191801767796278\n",
            "Epoch: 51 Loss: 0.018855277448892593\n",
            "Epoch: 52 Loss: 0.018615776672959328\n",
            "Epoch: 53 Loss: 0.018303057178854942\n",
            "Epoch: 54 Loss: 0.018036482855677605\n",
            "Epoch: 55 Loss: 0.017746267840266228\n",
            "Epoch: 56 Loss: 0.017507148906588554\n",
            "Epoch: 57 Loss: 0.01727294735610485\n",
            "Epoch: 58 Loss: 0.017054760828614235\n",
            "Epoch: 59 Loss: 0.016812561079859734\n",
            "Epoch: 60 Loss: 0.01656322367489338\n",
            "Epoch: 61 Loss: 0.016341617330908775\n",
            "Epoch: 62 Loss: 0.01612211763858795\n",
            "Epoch: 63 Loss: 0.015945060178637505\n",
            "Epoch: 64 Loss: 0.01570044830441475\n",
            "Epoch: 65 Loss: 0.015509963035583496\n",
            "Epoch: 66 Loss: 0.015330766327679157\n",
            "Epoch: 67 Loss: 0.015156533569097519\n",
            "Epoch: 68 Loss: 0.014993987046182156\n",
            "Epoch: 69 Loss: 0.014808290638029575\n",
            "Epoch: 70 Loss: 0.014630605466663837\n",
            "Epoch: 71 Loss: 0.014446322806179523\n",
            "Epoch: 72 Loss: 0.014294279739260674\n",
            "Epoch: 73 Loss: 0.014118660241365433\n",
            "Epoch: 74 Loss: 0.013989019207656384\n",
            "Epoch: 75 Loss: 0.013829865492880344\n",
            "Epoch: 76 Loss: 0.01367173157632351\n",
            "Epoch: 77 Loss: 0.013526295311748981\n",
            "Epoch: 78 Loss: 0.013381329365074635\n",
            "Epoch: 79 Loss: 0.013258536346256733\n",
            "Epoch: 80 Loss: 0.013116125017404556\n",
            "Epoch: 81 Loss: 0.012992064468562603\n",
            "Epoch: 82 Loss: 0.012837056070566177\n",
            "Epoch: 83 Loss: 0.012734781950712204\n",
            "Epoch: 84 Loss: 0.012604922987520695\n",
            "Epoch: 85 Loss: 0.012486133724451065\n",
            "Epoch: 86 Loss: 0.01236631628125906\n",
            "Epoch: 87 Loss: 0.012238053604960442\n",
            "Epoch: 88 Loss: 0.012135566212236881\n",
            "Epoch: 89 Loss: 0.01204066351056099\n",
            "Epoch: 90 Loss: 0.011933519504964352\n",
            "Epoch: 91 Loss: 0.011823084205389023\n",
            "Epoch: 92 Loss: 0.011719726957380772\n",
            "Epoch: 93 Loss: 0.0116471778601408\n",
            "Epoch: 94 Loss: 0.011531124822795391\n",
            "Epoch: 95 Loss: 0.011431138031184673\n",
            "Epoch: 96 Loss: 0.011325135827064514\n",
            "Epoch: 97 Loss: 0.011250569485127926\n",
            "Epoch: 98 Loss: 0.011168277822434902\n",
            "Epoch: 99 Loss: 0.011056458577513695\n",
            "Epoch: 100 Loss: 0.010981334373354912\n",
            "training finished, and state saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsbXq9AMujbH",
        "outputId": "e0f6e000-8252-4a56-c712-b2fb47d2ed55"
      },
      "source": [
        "# loading saved state\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Testing the neural network after training\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "  images, labels = data\n",
        "  outputs = net(images)\n",
        "  _, pred = outputs.max(1)\n",
        "  target = F.one_hot(labels, num_classes=10)\n",
        "  test_total += batch_size\n",
        "  correct = (pred == labels).sum()\n",
        "  test_correct += correct\n",
        "\n",
        "print(f'Correct: {test_correct} Incorrect: {test_total - test_correct}')\n",
        "print(f'Accuracy: {test_correct / test_total}')  "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct: 9873 Incorrect: 127\n",
            "Accuracy: 0.9872999787330627\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}